{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\LLAS\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>import Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Set Hiper Piramiter</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epoch = 200\n",
    "batch_size = 100\n",
    "learning_rate = 0.0001\n",
    "n_hidden = 256\n",
    "n_input = 28*28\n",
    "n_noise = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Setting Input Tendor</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Real data\n",
    "X = tf.placeholder(tf.float32,[None,n_input])\n",
    "#Noise data\n",
    "Z = tf.placeholder(tf.float32,[None,n_noise])\n",
    "#Not used Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Setting Tensor to Makes Hidden Layers</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_W1 = tf.Variable(tf.random_normal([n_noise, n_hidden],stddev=0.1))\n",
    "G_B1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "\n",
    "G_W2 = tf.Variable(tf.random_normal([n_hidden, n_input],stddev=0.1))\n",
    "G_B2 = tf.Variable(tf.zeros([n_input]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Setting Tensor to Makes Discriminator Layers</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_W1 = tf.Variable(tf.random_normal([n_input, n_hidden],stddev=0.1))\n",
    "D_B1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "\n",
    "D_W2 = tf.Variable(tf.random_normal([n_hidden, 1],stddev=0.1))\n",
    "D_B2 = tf.Variable(tf.zeros([1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Create Generator</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(noise_z):\n",
    "    hidden = tf.nn.relu( tf.matmul( noise_z, G_W1 ) + G_B1 )\n",
    "    output = tf.nn.sigmoid( tf.matmul( hidden, G_W2 ) + G_B2 )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Create Discriminator</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminaster(inputs):\n",
    "    hidden = tf.nn.relu( tf.matmul( inputs, D_W1 ) + D_B1 )\n",
    "    output = tf.nn.sigmoid( tf.matmul( hidden, D_W2) + D_B2 )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Function to Make Noise-Data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise(batch_size, n_noise):\n",
    "    return np.random.normal( size = ( batch_size, n_noise ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Maker Definition used Noise</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = generator(Z)\n",
    "D_gene  = discriminaster(G)\n",
    "D_real = discriminaster(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Definition to Loss functions</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_D = tf.reduce_mean( tf.log( D_real ) + tf.log( 1 - D_gene ) )\n",
    "loss_G = tf.reduce_mean( tf.log( D_gene ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Split G / D Variables</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_variable_list = [D_W1, D_B1, D_W2, D_B2]\n",
    "G_variable_list = [G_W1, G_B1, G_W2, G_B2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Optimizer Setting</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_D = tf.train.AdamOptimizer(learning_rate).minimize(-loss_D,var_list = D_variable_list)\n",
    "\n",
    "train_G = tf.train.AdamOptimizer(learning_rate).minimize(-loss_G,var_list = G_variable_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Setting etc....</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "loss_val_D = 0\n",
    "loss_val_G = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Make Tensor-Flow Session</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  0000 D loss : { -1.4059366 } G loss : { -0.88408226 }\n",
      "Epoch :  0000 D loss : { -1.2918143 } G loss : { -1.0393975 }\n",
      "Epoch :  0000 D loss : { -1.2039573 } G loss : { -1.1979184 }\n",
      "Epoch :  0000 D loss : { -1.1923767 } G loss : { -1.2979213 }\n",
      "Epoch :  0000 D loss : { -1.0425956 } G loss : { -1.431214 }\n",
      "Epoch :  0000 D loss : { -0.96063775 } G loss : { -1.5957322 }\n",
      "Epoch :  0000 D loss : { -0.91984224 } G loss : { -1.6740143 }\n",
      "Epoch :  0000 D loss : { -0.92220175 } G loss : { -1.7873476 }\n",
      "Epoch :  0000 D loss : { -0.90639997 } G loss : { -1.8569092 }\n",
      "Epoch :  0000 D loss : { -0.85036296 } G loss : { -2.003079 }\n",
      "Epoch :  0000 D loss : { -0.73077315 } G loss : { -2.0458395 }\n",
      "Epoch :  0000 D loss : { -0.8134384 } G loss : { -2.0953226 }\n",
      "Epoch :  0000 D loss : { -0.71292466 } G loss : { -2.204676 }\n",
      "Epoch :  0000 D loss : { -0.72721726 } G loss : { -2.3149178 }\n",
      "Epoch :  0000 D loss : { -0.68811804 } G loss : { -2.1708643 }\n",
      "Epoch :  0000 D loss : { -0.6881264 } G loss : { -2.2822526 }\n",
      "Epoch :  0000 D loss : { -0.664739 } G loss : { -2.34999 }\n",
      "Epoch :  0000 D loss : { -0.6860863 } G loss : { -2.2998583 }\n",
      "Epoch :  0000 D loss : { -0.61138934 } G loss : { -2.3713815 }\n",
      "Epoch :  0000 D loss : { -0.59656584 } G loss : { -2.242945 }\n",
      "Epoch :  0000 D loss : { -0.5297787 } G loss : { -2.287102 }\n",
      "Epoch :  0000 D loss : { -0.5608592 } G loss : { -2.374882 }\n",
      "Epoch :  0000 D loss : { -0.59298605 } G loss : { -2.2780828 }\n",
      "Epoch :  0000 D loss : { -0.53790784 } G loss : { -2.3044016 }\n",
      "Epoch :  0000 D loss : { -0.56396633 } G loss : { -2.3183393 }\n",
      "Epoch :  0000 D loss : { -0.49642047 } G loss : { -2.3668706 }\n",
      "Epoch :  0000 D loss : { -0.47849354 } G loss : { -2.3096566 }\n",
      "Epoch :  0000 D loss : { -0.51148707 } G loss : { -2.3588934 }\n",
      "Epoch :  0000 D loss : { -0.4767487 } G loss : { -2.3820877 }\n",
      "Epoch :  0000 D loss : { -0.48642159 } G loss : { -2.293023 }\n",
      "Epoch :  0000 D loss : { -0.4839137 } G loss : { -2.372841 }\n",
      "Epoch :  0000 D loss : { -0.43127716 } G loss : { -2.4083078 }\n",
      "Epoch :  0000 D loss : { -0.4323017 } G loss : { -2.350944 }\n",
      "Epoch :  0000 D loss : { -0.45127064 } G loss : { -2.2812738 }\n",
      "Epoch :  0000 D loss : { -0.38326177 } G loss : { -2.3410103 }\n",
      "Epoch :  0000 D loss : { -0.39597243 } G loss : { -2.4008079 }\n",
      "Epoch :  0000 D loss : { -0.44816428 } G loss : { -2.3720074 }\n",
      "Epoch :  0000 D loss : { -0.39330834 } G loss : { -2.4284425 }\n",
      "Epoch :  0000 D loss : { -0.35560197 } G loss : { -2.5016737 }\n",
      "Epoch :  0000 D loss : { -0.39622414 } G loss : { -2.4516408 }\n",
      "Epoch :  0000 D loss : { -0.35259655 } G loss : { -2.519517 }\n",
      "Epoch :  0000 D loss : { -0.37192944 } G loss : { -2.5571737 }\n",
      "Epoch :  0000 D loss : { -0.3461982 } G loss : { -2.579214 }\n",
      "Epoch :  0000 D loss : { -0.33528388 } G loss : { -2.6923852 }\n",
      "Epoch :  0000 D loss : { -0.31343693 } G loss : { -2.6598327 }\n",
      "Epoch :  0000 D loss : { -0.3128148 } G loss : { -2.7961872 }\n",
      "Epoch :  0000 D loss : { -0.3201522 } G loss : { -2.6788206 }\n",
      "Epoch :  0000 D loss : { -0.33399817 } G loss : { -2.8349628 }\n",
      "Epoch :  0000 D loss : { -0.3634379 } G loss : { -2.624746 }\n",
      "Epoch :  0000 D loss : { -0.3098303 } G loss : { -2.7190583 }\n",
      "Epoch :  0000 D loss : { -0.2944832 } G loss : { -2.7843597 }\n",
      "Epoch :  0000 D loss : { -0.29797965 } G loss : { -2.8594012 }\n",
      "Epoch :  0000 D loss : { -0.26786652 } G loss : { -2.8863783 }\n",
      "Epoch :  0000 D loss : { -0.28892845 } G loss : { -2.9953578 }\n",
      "Epoch :  0000 D loss : { -0.27884683 } G loss : { -2.8695557 }\n",
      "Epoch :  0000 D loss : { -0.26980215 } G loss : { -2.8851438 }\n",
      "Epoch :  0000 D loss : { -0.25711837 } G loss : { -2.907434 }\n",
      "Epoch :  0000 D loss : { -0.26423624 } G loss : { -2.9559145 }\n",
      "Epoch :  0000 D loss : { -0.22945948 } G loss : { -2.962843 }\n",
      "Epoch :  0000 D loss : { -0.23702735 } G loss : { -2.9014761 }\n",
      "Epoch :  0000 D loss : { -0.28406164 } G loss : { -2.9895172 }\n",
      "Epoch :  0000 D loss : { -0.2225239 } G loss : { -3.0191543 }\n",
      "Epoch :  0000 D loss : { -0.2203414 } G loss : { -3.0571775 }\n",
      "Epoch :  0000 D loss : { -0.24661958 } G loss : { -3.02232 }\n",
      "Epoch :  0000 D loss : { -0.24426483 } G loss : { -3.0487525 }\n",
      "Epoch :  0000 D loss : { -0.25017953 } G loss : { -3.1723359 }\n",
      "Epoch :  0000 D loss : { -0.24075353 } G loss : { -3.099334 }\n",
      "Epoch :  0000 D loss : { -0.21110158 } G loss : { -3.180592 }\n",
      "Epoch :  0000 D loss : { -0.2335792 } G loss : { -2.9351494 }\n",
      "Epoch :  0000 D loss : { -0.24544525 } G loss : { -3.006039 }\n",
      "Epoch :  0000 D loss : { -0.2077753 } G loss : { -3.2059126 }\n",
      "Epoch :  0000 D loss : { -0.23148201 } G loss : { -3.1724055 }\n",
      "Epoch :  0000 D loss : { -0.188167 } G loss : { -3.2899024 }\n",
      "Epoch :  0000 D loss : { -0.20795125 } G loss : { -3.2362597 }\n",
      "Epoch :  0000 D loss : { -0.24535035 } G loss : { -3.0872135 }\n",
      "Epoch :  0000 D loss : { -0.19771561 } G loss : { -3.25508 }\n",
      "Epoch :  0000 D loss : { -0.19610548 } G loss : { -3.436626 }\n",
      "Epoch :  0000 D loss : { -0.22754861 } G loss : { -3.1199262 }\n",
      "Epoch :  0000 D loss : { -0.1924841 } G loss : { -3.3225024 }\n",
      "Epoch :  0000 D loss : { -0.1678468 } G loss : { -3.273986 }\n",
      "Epoch :  0000 D loss : { -0.20919725 } G loss : { -3.3393426 }\n",
      "Epoch :  0000 D loss : { -0.20379049 } G loss : { -3.3262823 }\n",
      "Epoch :  0000 D loss : { -0.1526011 } G loss : { -3.4401324 }\n",
      "Epoch :  0000 D loss : { -0.17300722 } G loss : { -3.5000947 }\n",
      "Epoch :  0000 D loss : { -0.20702758 } G loss : { -3.278349 }\n",
      "Epoch :  0000 D loss : { -0.17549282 } G loss : { -3.2444086 }\n",
      "Epoch :  0000 D loss : { -0.20746294 } G loss : { -3.2965393 }\n",
      "Epoch :  0000 D loss : { -0.16153015 } G loss : { -3.3930123 }\n",
      "Epoch :  0000 D loss : { -0.19166312 } G loss : { -3.3066032 }\n",
      "Epoch :  0000 D loss : { -0.16738944 } G loss : { -3.3113356 }\n",
      "Epoch :  0000 D loss : { -0.17578281 } G loss : { -3.4294038 }\n",
      "Epoch :  0000 D loss : { -0.17680466 } G loss : { -3.3720891 }\n",
      "Epoch :  0000 D loss : { -0.17966539 } G loss : { -3.366374 }\n",
      "Epoch :  0000 D loss : { -0.17778713 } G loss : { -3.5159903 }\n",
      "Epoch :  0000 D loss : { -0.17969117 } G loss : { -3.5060315 }\n",
      "Epoch :  0000 D loss : { -0.16901079 } G loss : { -3.4814768 }\n",
      "Epoch :  0000 D loss : { -0.16659684 } G loss : { -3.3792822 }\n",
      "Epoch :  0000 D loss : { -0.14355092 } G loss : { -3.5710306 }\n",
      "Epoch :  0000 D loss : { -0.16479178 } G loss : { -3.4640908 }\n",
      "Epoch :  0000 D loss : { -0.16108517 } G loss : { -3.430763 }\n",
      "Epoch :  0000 D loss : { -0.1569386 } G loss : { -3.590825 }\n",
      "Epoch :  0000 D loss : { -0.1861419 } G loss : { -3.4908226 }\n",
      "Epoch :  0000 D loss : { -0.15036291 } G loss : { -3.6056974 }\n",
      "Epoch :  0000 D loss : { -0.15123299 } G loss : { -3.6575434 }\n",
      "Epoch :  0000 D loss : { -0.16674498 } G loss : { -3.6461494 }\n",
      "Epoch :  0000 D loss : { -0.14380088 } G loss : { -3.6328743 }\n",
      "Epoch :  0000 D loss : { -0.16785985 } G loss : { -3.4823062 }\n",
      "Epoch :  0000 D loss : { -0.14974129 } G loss : { -3.775405 }\n",
      "Epoch :  0000 D loss : { -0.15022255 } G loss : { -3.5948799 }\n",
      "Epoch :  0000 D loss : { -0.17443198 } G loss : { -3.5443516 }\n",
      "Epoch :  0000 D loss : { -0.14746107 } G loss : { -3.6114347 }\n",
      "Epoch :  0000 D loss : { -0.15823705 } G loss : { -3.5653403 }\n",
      "Epoch :  0000 D loss : { -0.14236663 } G loss : { -3.6790476 }\n",
      "Epoch :  0000 D loss : { -0.1331512 } G loss : { -3.6057005 }\n",
      "Epoch :  0000 D loss : { -0.12238083 } G loss : { -3.7922657 }\n",
      "Epoch :  0000 D loss : { -0.1507626 } G loss : { -3.83976 }\n",
      "Epoch :  0000 D loss : { -0.14828014 } G loss : { -3.7028456 }\n",
      "Epoch :  0000 D loss : { -0.14144742 } G loss : { -3.8328793 }\n",
      "Epoch :  0000 D loss : { -0.13679653 } G loss : { -3.7736795 }\n",
      "Epoch :  0000 D loss : { -0.12133371 } G loss : { -3.779879 }\n",
      "Epoch :  0000 D loss : { -0.11010353 } G loss : { -3.8007758 }\n",
      "Epoch :  0000 D loss : { -0.14461924 } G loss : { -3.7452657 }\n",
      "Epoch :  0000 D loss : { -0.11926754 } G loss : { -3.5533001 }\n",
      "Epoch :  0000 D loss : { -0.10814645 } G loss : { -3.9188223 }\n",
      "Epoch :  0000 D loss : { -0.117228635 } G loss : { -3.794774 }\n",
      "Epoch :  0000 D loss : { -0.10550148 } G loss : { -3.885426 }\n",
      "Epoch :  0000 D loss : { -0.12104977 } G loss : { -3.691126 }\n",
      "Epoch :  0000 D loss : { -0.13869257 } G loss : { -3.8109586 }\n",
      "Epoch :  0000 D loss : { -0.111717284 } G loss : { -3.7627265 }\n",
      "Epoch :  0000 D loss : { -0.15954146 } G loss : { -3.550316 }\n",
      "Epoch :  0000 D loss : { -0.1442407 } G loss : { -3.7781 }\n",
      "Epoch :  0000 D loss : { -0.1105336 } G loss : { -3.9496844 }\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch :  0000 D loss : { -0.11524801 } G loss : { -3.8227243 }\n",
      "Epoch :  0000 D loss : { -0.102114104 } G loss : { -4.0113277 }\n",
      "Epoch :  0000 D loss : { -0.122872286 } G loss : { -3.9394054 }\n",
      "Epoch :  0000 D loss : { -0.1282094 } G loss : { -4.0173273 }\n",
      "Epoch :  0000 D loss : { -0.11190346 } G loss : { -4.0593624 }\n",
      "Epoch :  0000 D loss : { -0.1058302 } G loss : { -3.985039 }\n",
      "Epoch :  0000 D loss : { -0.117833726 } G loss : { -3.976546 }\n",
      "Epoch :  0000 D loss : { -0.111006305 } G loss : { -3.9760327 }\n",
      "Epoch :  0000 D loss : { -0.13458453 } G loss : { -3.9148898 }\n",
      "Epoch :  0000 D loss : { -0.10175331 } G loss : { -3.895098 }\n",
      "Epoch :  0000 D loss : { -0.10922174 } G loss : { -4.050093 }\n",
      "Epoch :  0000 D loss : { -0.10441323 } G loss : { -3.9984565 }\n",
      "Epoch :  0000 D loss : { -0.11222267 } G loss : { -3.9966168 }\n",
      "Epoch :  0000 D loss : { -0.09270706 } G loss : { -3.9254334 }\n",
      "Epoch :  0000 D loss : { -0.103928894 } G loss : { -4.010281 }\n",
      "Epoch :  0000 D loss : { -0.10574112 } G loss : { -3.8581629 }\n",
      "Epoch :  0000 D loss : { -0.11917141 } G loss : { -3.9070983 }\n",
      "Epoch :  0000 D loss : { -0.113024786 } G loss : { -3.9975097 }\n",
      "Epoch :  0000 D loss : { -0.11133915 } G loss : { -4.1316056 }\n",
      "Epoch :  0000 D loss : { -0.10910468 } G loss : { -3.7911303 }\n",
      "Epoch :  0000 D loss : { -0.123703934 } G loss : { -3.9993086 }\n",
      "Epoch :  0000 D loss : { -0.09604294 } G loss : { -4.0981865 }\n",
      "Epoch :  0000 D loss : { -0.099835016 } G loss : { -3.9402838 }\n",
      "Epoch :  0000 D loss : { -0.097630955 } G loss : { -3.9886384 }\n",
      "Epoch :  0000 D loss : { -0.10065613 } G loss : { -4.045972 }\n",
      "Epoch :  0000 D loss : { -0.08987031 } G loss : { -4.011102 }\n",
      "Epoch :  0000 D loss : { -0.111624815 } G loss : { -3.9833865 }\n",
      "Epoch :  0000 D loss : { -0.105526745 } G loss : { -3.957982 }\n",
      "Epoch :  0000 D loss : { -0.09498057 } G loss : { -4.1496544 }\n",
      "Epoch :  0000 D loss : { -0.10483766 } G loss : { -4.1433563 }\n",
      "Epoch :  0000 D loss : { -0.102384225 } G loss : { -3.9414778 }\n",
      "Epoch :  0000 D loss : { -0.086081415 } G loss : { -4.055344 }\n",
      "Epoch :  0000 D loss : { -0.08055603 } G loss : { -3.9358222 }\n",
      "Epoch :  0000 D loss : { -0.09442827 } G loss : { -4.26466 }\n",
      "Epoch :  0000 D loss : { -0.09222895 } G loss : { -4.268917 }\n",
      "Epoch :  0000 D loss : { -0.08386657 } G loss : { -4.268212 }\n",
      "Epoch :  0000 D loss : { -0.08043583 } G loss : { -4.1014147 }\n",
      "Epoch :  0000 D loss : { -0.09277012 } G loss : { -4.2919326 }\n",
      "Epoch :  0000 D loss : { -0.072239816 } G loss : { -4.265009 }\n",
      "Epoch :  0000 D loss : { -0.08289555 } G loss : { -4.2281685 }\n",
      "Epoch :  0000 D loss : { -0.08803123 } G loss : { -4.189789 }\n",
      "Epoch :  0000 D loss : { -0.09489832 } G loss : { -4.125399 }\n",
      "Epoch :  0000 D loss : { -0.090775356 } G loss : { -4.162591 }\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(total_epoch):\n",
    "    for i in range(total_batch):\n",
    "        \n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        noise = get_noise(batch_size, n_noise)\n",
    "        \n",
    "        _, loss_val_D = sess.run( [ train_D, loss_D ], feed_dict = { X: batch_xs, Z: noise } )\n",
    "        _, loss_val_G = sess.run( [ train_G, loss_G ], feed_dict = { Z: noise } )\n",
    "        \n",
    "        print('Epoch : ', '%04d' % epoch, 'D loss : {',loss_val_D,'}', 'G loss : {',loss_val_G,'}')\n",
    "        \n",
    "        if( epoch == 0 or ( epoch + 1 ) % 10 == 0 ):\n",
    "            sample_size=10\n",
    "            noise = get_noise(sample_size , n_noise)\n",
    "            samples = sess.run(G,feed_dict={Z:noise})\n",
    "            \n",
    "            fig, ax = plt.subplots(1,sample_size,figsize=(sample_size,1))\n",
    "            \n",
    "            for i in range(sample_size):\n",
    "                ax[i].set_axis_off()\n",
    "                ax[i].imshow(np.reshape(samples[i],(28,28)))\n",
    "                \n",
    "            plt.savefig('sample{}.png'.format(str(epoch).zfill(3)),bbox_inches='tight')\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
